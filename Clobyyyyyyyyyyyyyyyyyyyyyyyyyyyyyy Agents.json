{
  "nodes": [
    {
      "id": "worker_0",
      "position": {
        "x": 537.0386420632192,
        "y": 1173.9097465636626
      },
      "type": "customNode",
      "data": {
        "id": "worker_0",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_0-input-workerName-string"
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_0-input-workerPrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_0-input-promptValues-json"
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_0-input-maxIterations-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_0-input-tools-Tool"
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_0-input-supervisor-Supervisor"
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_0-input-model-BaseChatModel"
          }
        ],
        "inputs": {
          "workerName": "Extractor ",
          "workerPrompt": "As a Data Extractor, your role is to gather and extract relevant data from various sources as directed by the Supervisor. Your work forms the foundation for further processes, ensuring that accurate and comprehensive data is available for analysis and response creation.\n\nObjectives:\n\nEfficient Data Extraction: Upon receiving a trigger from the Supervisor, promptly extract the necessary data from specified sources.\nData Accuracy and Organization: Ensure that the data is accurate, relevant, and well-organized for the next stage of processing.\nData Set Preparation: Produce a detailed data set that includes all required information, structured for easy access and understanding by the Response Writer.\nInstructions:\n\nAvoid assumptions and rely solely on verified data sources.\nEnsure the data set is comprehensive and formatted to facilitate seamless processing by the Response Writer.\nCommunicate any data extraction issues or anomalies to the Supervisor immediately.\n",
          "tools": [
            "{{retrieverTool_1.data.instance}}"
          ],
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 727,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 537.0386420632192,
        "y": 1173.9097465636626
      }
    },
    {
      "id": "retrieverTool_1",
      "position": {
        "x": 121.36675751198385,
        "y": 1221.2507845811747
      },
      "type": "customNode",
      "data": {
        "id": "retrieverTool_1",
        "label": "Retriever Tool",
        "version": 3,
        "name": "retrieverTool",
        "type": "RetrieverTool",
        "baseClasses": [
          "RetrieverTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a retriever as allowed tool for agent",
        "inputParams": [
          {
            "label": "Retriever Name",
            "name": "name",
            "type": "string",
            "placeholder": "search_state_of_union",
            "id": "retrieverTool_1-input-name-string"
          },
          {
            "label": "Retriever Description",
            "name": "description",
            "type": "string",
            "description": "When should agent uses to retrieve documents",
            "rows": 3,
            "placeholder": "Searches and returns documents regarding the state-of-the-union.",
            "id": "retrieverTool_1-input-description-string"
          },
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "retrieverTool_1-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Additional Metadata Filter",
            "name": "retrieverToolMetadataFilter",
            "type": "json",
            "description": "Add additional metadata filter on top of the existing filter from vector store",
            "optional": true,
            "additionalParams": true,
            "hint": {
              "label": "What can you filter?",
              "value": "Add additional filters to vector store. You can also filter with flow config, including the current \"state\":\n- `$flow.sessionId`\n- `$flow.chatId`\n- `$flow.chatflowId`\n- `$flow.input`\n- `$flow.state`\n"
            },
            "id": "retrieverTool_1-input-retrieverToolMetadataFilter-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Retriever",
            "name": "retriever",
            "type": "BaseRetriever",
            "id": "retrieverTool_1-input-retriever-BaseRetriever"
          }
        ],
        "inputs": {
          "name": "file_retriever",
          "description": "Only fetch existing data",
          "retriever": "{{memoryVectorStore_0.data.instance}}",
          "returnSourceDocuments": "",
          "retrieverToolMetadataFilter": ""
        },
        "outputAnchors": [
          {
            "id": "retrieverTool_1-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "retrieverTool",
            "label": "RetrieverTool",
            "description": "Use a retriever as allowed tool for agent",
            "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 660,
      "selected": false,
      "positionAbsolute": {
        "x": 121.36675751198385,
        "y": 1221.2507845811747
      },
      "dragging": false
    },
    {
      "id": "memoryVectorStore_0",
      "position": {
        "x": -335.6036187264311,
        "y": 1187.2013694840127
      },
      "type": "customNode",
      "data": {
        "id": "memoryVectorStore_0",
        "label": "In-Memory Vector Store",
        "version": 1,
        "name": "memoryVectorStore",
        "type": "Memory",
        "baseClasses": [
          "Memory",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
        "inputParams": [
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "optional": true,
            "id": "memoryVectorStore_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "memoryVectorStore_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "memoryVectorStore_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{jsonFile_0.data.instance}}",
            "{{fileLoader_0.data.instance}}"
          ],
          "embeddings": "{{openAIEmbeddings_0.data.instance}}",
          "topK": "223"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Memory Retriever",
                "description": "",
                "type": "Memory | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                "name": "vectorStore",
                "label": "Memory Vector Store",
                "description": "",
                "type": "Memory | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 411,
      "selected": false,
      "positionAbsolute": {
        "x": -335.6036187264311,
        "y": 1187.2013694840127
      },
      "dragging": false
    },
    {
      "id": "openAIEmbeddings_0",
      "position": {
        "x": -749.006817074363,
        "y": 1449.3318738875646
      },
      "type": "customNode",
      "data": {
        "id": "openAIEmbeddings_0",
        "label": "OpenAI Embeddings",
        "version": 4,
        "name": "openAIEmbeddings",
        "type": "OpenAIEmbeddings",
        "baseClasses": [
          "OpenAIEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "OpenAI API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "openAIEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "text-embedding-ada-002",
            "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
          },
          {
            "label": "Strip New Lines",
            "name": "stripNewLines",
            "type": "boolean",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
          },
          {
            "label": "Batch Size",
            "name": "batchSize",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-batchSize-number"
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-timeout-number"
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-basepath-string"
          },
          {
            "label": "Dimensions",
            "name": "dimensions",
            "type": "number",
            "optional": true,
            "additionalParams": true,
            "id": "openAIEmbeddings_0-input-dimensions-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "text-embedding-ada-002",
          "stripNewLines": "",
          "batchSize": "",
          "timeout": "",
          "basepath": "",
          "dimensions": ""
        },
        "outputAnchors": [
          {
            "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "name": "openAIEmbeddings",
            "label": "OpenAIEmbeddings",
            "description": "OpenAI API to generate embeddings for a given text",
            "type": "OpenAIEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 429,
      "selected": false,
      "positionAbsolute": {
        "x": -749.006817074363,
        "y": 1449.3318738875646
      },
      "dragging": false
    },
    {
      "id": "fileLoader_0",
      "position": {
        "x": -787.8097125749697,
        "y": 924.6592747195994
      },
      "type": "customNode",
      "data": {
        "id": "fileLoader_0",
        "label": "File Loader",
        "version": 2,
        "name": "fileLoader",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "A generic file loader that can load txt, json, csv, docx, pdf, and other files",
        "inputParams": [
          {
            "label": "File",
            "name": "file",
            "type": "file",
            "fileType": "*",
            "id": "fileLoader_0-input-file-file",
            "display": true
          },
          {
            "label": "Pdf Usage",
            "name": "usage",
            "type": "options",
            "description": "Only when loading PDF files",
            "options": [
              {
                "label": "One document per page",
                "name": "perPage"
              },
              {
                "label": "One document per file",
                "name": "perFile"
              }
            ],
            "default": "perPage",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-usage-options",
            "display": true
          },
          {
            "label": "Use Legacy Build",
            "name": "legacyBuild",
            "type": "boolean",
            "description": "Use legacy build for PDF compatibility issues",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-legacyBuild-boolean",
            "display": true
          },
          {
            "label": "JSONL Pointer Extraction",
            "name": "pointerName",
            "type": "string",
            "description": "Only when loading JSONL files",
            "placeholder": "<pointerName>",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-pointerName-string",
            "display": true
          },
          {
            "label": "Additional Metadata",
            "name": "metadata",
            "type": "json",
            "description": "Additional metadata to be added to the extracted documents",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-metadata-json",
            "display": true
          },
          {
            "label": "Omit Metadata Keys",
            "name": "omitMetadataKeys",
            "type": "string",
            "rows": 4,
            "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
            "placeholder": "key1, key2, key3.nestedKey1",
            "optional": true,
            "additionalParams": true,
            "id": "fileLoader_0-input-omitMetadataKeys-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "fileLoader_0-input-textSplitter-TextSplitter",
            "display": true
          }
        ],
        "inputs": {
          "textSplitter": "",
          "usage": "perPage",
          "legacyBuild": "",
          "pointerName": "",
          "metadata": "",
          "omitMetadataKeys": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "fileLoader_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "fileLoader_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "document"
        },
        "selected": false
      },
      "width": 300,
      "height": 444,
      "selected": false,
      "positionAbsolute": {
        "x": -787.8097125749697,
        "y": 924.6592747195994
      },
      "dragging": false
    },
    {
      "id": "chatOpenAI_0",
      "position": {
        "x": -347.6436369746125,
        "y": 307.4058401833372
      },
      "type": "customNode",
      "data": {
        "id": "chatOpenAI_0",
        "label": "ChatOpenAI",
        "version": 8.2,
        "name": "chatOpenAI",
        "type": "ChatOpenAI",
        "baseClasses": [
          "ChatOpenAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "openAIApi"
            ],
            "id": "chatOpenAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gpt-4o-mini",
            "id": "chatOpenAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatOpenAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-maxTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Frequency Penalty",
            "name": "frequencyPenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-frequencyPenalty-number",
            "display": true
          },
          {
            "label": "Presence Penalty",
            "name": "presencePenalty",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-presencePenalty-number",
            "display": true
          },
          {
            "label": "Timeout",
            "name": "timeout",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-timeout-number",
            "display": true
          },
          {
            "label": "Strict Tool Calling",
            "name": "strictToolCalling",
            "type": "boolean",
            "description": "Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-strictToolCalling-boolean",
            "display": true
          },
          {
            "label": "Stop Sequence",
            "name": "stopSequence",
            "type": "string",
            "rows": 4,
            "optional": true,
            "description": "List of stop words to use when generating. Use comma to separate multiple stop words.",
            "additionalParams": true,
            "id": "chatOpenAI_0-input-stopSequence-string",
            "display": true
          },
          {
            "label": "BasePath",
            "name": "basepath",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-basepath-string",
            "display": true
          },
          {
            "label": "Proxy Url",
            "name": "proxyUrl",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-proxyUrl-string",
            "display": true
          },
          {
            "label": "BaseOptions",
            "name": "baseOptions",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-baseOptions-json",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatOpenAI_0-input-allowImageUploads-boolean",
            "display": true
          },
          {
            "label": "Image Resolution",
            "description": "This parameter controls the resolution in which the model views the image.",
            "name": "imageResolution",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "High",
                "name": "high"
              },
              {
                "label": "Auto",
                "name": "auto"
              }
            ],
            "default": "low",
            "optional": false,
            "show": {
              "allowImageUploads": true
            },
            "id": "chatOpenAI_0-input-imageResolution-options",
            "display": false
          },
          {
            "label": "Reasoning Effort",
            "description": "Constrains effort on reasoning for reasoning models. Only applicable for o1 and o3 models.",
            "name": "reasoningEffort",
            "type": "options",
            "options": [
              {
                "label": "Low",
                "name": "low"
              },
              {
                "label": "Medium",
                "name": "medium"
              },
              {
                "label": "High",
                "name": "high"
              }
            ],
            "default": "medium",
            "optional": false,
            "additionalParams": true,
            "id": "chatOpenAI_0-input-reasoningEffort-options",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatOpenAI_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "gpt-4o-mini",
          "temperature": "0.7",
          "streaming": true,
          "maxTokens": "",
          "topP": "",
          "frequencyPenalty": "",
          "presencePenalty": "",
          "timeout": "",
          "strictToolCalling": "",
          "stopSequence": "",
          "basepath": "",
          "proxyUrl": "",
          "baseOptions": "",
          "allowImageUploads": "",
          "imageResolution": "low",
          "reasoningEffort": "medium"
        },
        "outputAnchors": [
          {
            "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatOpenAI",
            "label": "ChatOpenAI",
            "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
            "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 675,
      "selected": false,
      "positionAbsolute": {
        "x": -347.6436369746125,
        "y": 307.4058401833372
      },
      "dragging": false
    },
    {
      "id": "worker_1",
      "position": {
        "x": 902.1969346349247,
        "y": 331.085283205058
      },
      "type": "customNode",
      "data": {
        "id": "worker_1",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_1-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_1-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_1-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_1-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_1-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_1-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_1-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "Response Writer",
          "workerPrompt": "As a Response Writer, your task is to transform the data extracted by the Data Extractor into well-informed, precise, and insightful responses. Your role is crucial in converting raw data into actionable insights or communications that are tailored to the specific needs of the end-user or client.\nObjectives:\n\nData Analysis and Interpretation: Upon receiving extracted data, thoroughly analyze and interpret the information to produce comprehensive responses that go beyond surface-level observations.\nResponse Creation: Craft responses that are clear, concise, and contextually relevant, aligned with the objectives set by the Supervisor.\nKnowledge Application: Leverage your extensive built-in knowledge base to supplement the extracted data with relevant context, industry standards, best practices, or comparative insights when appropriate.\nProfessional Tone and Style: Maintain professionalism in your writing, adapting tone and style to be appropriate for the intended audience and communication purpose.\n\nInstructions:\n\nBegin by carefully reviewing the extracted data and clearly understanding the specific requirements or questions being addressed.\nDraw connections between the provided data and your pre-existing knowledge to identify patterns, implications, or additional insights that may be valuable to the end-user.\nWhen appropriate, enrich responses with:\n\nRelevant background information\nContextual explanations that aid understanding\nReal-world applications or examples\nPotential limitations of the provided data\nAlternative perspectives or approaches\n\n\nSupport all assertions with either the extracted data provided or clearly indicated general knowledge.\nMaintain appropriate citation practices when referencing information beyond the provided data.\nAvoid assumptions and ensure clarity, accuracy, and logical flow in your writing.\nCommunicate any discrepancies, data gaps, or issues with the data to the Supervisor for resolution.\nBalance technical precision with accessibility based on the target audience's expertise level.\n\nRemember: Your goal is to deliver value by thoughtfully integrating provided data with appropriate general knowledge, creating responses that are both data-driven and contextually enriched.",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 727,
      "selected": false,
      "positionAbsolute": {
        "x": 902.1969346349247,
        "y": 331.085283205058
      },
      "dragging": false
    },
    {
      "id": "supervisor_0",
      "position": {
        "x": 154.90060723214413,
        "y": 414.9301198598523
      },
      "type": "customNode",
      "data": {
        "id": "supervisor_0",
        "label": "Supervisor",
        "version": 3,
        "name": "supervisor",
        "type": "Supervisor",
        "baseClasses": [
          "Supervisor"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Supervisor Name",
            "name": "supervisorName",
            "type": "string",
            "placeholder": "Supervisor",
            "default": "Supervisor",
            "id": "supervisor_0-input-supervisorName-string",
            "display": true
          },
          {
            "label": "Supervisor Prompt",
            "name": "supervisorPrompt",
            "type": "string",
            "description": "Prompt must contains {team_members}",
            "rows": 4,
            "default": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
            "additionalParams": true,
            "id": "supervisor_0-input-supervisorPrompt-string",
            "display": true
          },
          {
            "label": "Summarization",
            "name": "summarization",
            "type": "boolean",
            "description": "Return final output as a summarization of the conversation",
            "optional": true,
            "additionalParams": true,
            "id": "supervisor_0-input-summarization-boolean",
            "display": true
          },
          {
            "label": "Recursion Limit",
            "name": "recursionLimit",
            "type": "number",
            "description": "Maximum number of times a call can recurse. If not provided, defaults to 100.",
            "default": 100,
            "additionalParams": true,
            "id": "supervisor_0-input-recursionLimit-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, GroqChat. Best result with GPT-4 model",
            "id": "supervisor_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Agent Memory",
            "name": "agentMemory",
            "type": "BaseCheckpointSaver",
            "description": "Save the state of the agent",
            "optional": true,
            "id": "supervisor_0-input-agentMemory-BaseCheckpointSaver",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "supervisor_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "supervisorName": "Supervisor",
          "supervisorPrompt": "You are a supervisor tasked with managing a conversation between the following workers: {team_members}.\nGiven the following user request, respond with the worker to act next.\nEach worker will perform a task and respond with their results and status.\nuse Input Evaluator first, then Extractor to get info, if they are asking to predict something not existing, use Predictor, use sentimental as fallback or for comprehensive question, use Response Writer to interpret the output to user\nWhen finished, respond with FINISH.\nSelect strategically to minimize the number of steps taken.",
          "model": "{{chatOpenAI_0.data.instance}}",
          "agentMemory": "",
          "summarization": "",
          "recursionLimit": 100,
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "supervisor_0-output-supervisor-Supervisor",
            "name": "supervisor",
            "label": "Supervisor",
            "description": "",
            "type": "Supervisor"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 488,
      "positionAbsolute": {
        "x": 154.90060723214413,
        "y": 414.9301198598523
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "worker_2",
      "position": {
        "x": 591.4862581166752,
        "y": 339.97291641358686
      },
      "type": "customNode",
      "data": {
        "id": "worker_2",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_2-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_2-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_2-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_2-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_2-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_2-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_2-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "Input Evaluator",
          "workerPrompt": "As the Input Evaluator, your primary responsibility is to accurately classify incoming tasks to ensure they are directed to the appropriate AI agents. This classification optimizes workflow efficiency and enhances task management effectiveness.\n\nObjective:\n\nYour goal is to determine whether a given task involves \"Data Extraction\" or \"Content Writing on Extracted Data.\"  This distinction is crucial for proper task assignment.\n\nInstructions:\n\nTask Analysis:\n\nThoroughly examine the provided task_description.\nIdentify key indicators within the language and context that specify the task's nature.\nClassification Criteria:\n\nData Extraction: Look for terms related to collecting, gathering, retrieving, or extracting data from sources.\nContent Writing on Extracted Data: Identify phrases indicating analysis, interpretation, or writing based on pre-existing data.\nOutput Requirements:\n\nProvide a clear classification of the task as either \"Data Extraction\" or \"Content Writing on Extracted Data.\"\nInclude a brief justification for your classification, citing specific elements from the task_description that informed your decision.\nTask Management:\n\nSubmit your classification and justification to the task management system for further processing.\nGuidelines:\n\nAvoid assumptions; rely solely on explicit cues within the task_description. if low confidence is low then ask for clarification, before classifyin as sentimental , make sure theres no data thats readily available that can be used to answer the user\nEnsure clarity and precision in your classification to facilitate seamless task routing.\nAnnotations and Explanations of Changes:\n\nStructure and Clarity:\n\nOrganized the prompt into distinct sections (Role Overview, Objective, Instructions, Guidelines) for better readability and comprehension.\nObjective Specification:\n\nClearly stated the objective to focus the agent on the task's primary goal.\nDetailed Instructions:\n\nProvided step-by-step instructions for task analysis and classification, ensuring the agent knows exactly what to do.\nClassification Criteria:\n\nAdded specific criteria for distinguishing between \"Data Extraction\" and \"Content Writing on Extracted Data,\" guiding the agent in making accurate classifications.\nOutput Requirements:\n\nClarified the expected output format, emphasizing the need for a justification to support the classification.\nGuidelines:\n\nIncluded guidelines to reinforce the importance of relying on explicit cues and maintaining clarity in outputs.\n\n\nif sentimental, explain why its not asking existing data and print all existing factors thats available and verify if any of them is related to user request in any form",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 727,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 591.4862581166752,
        "y": 339.97291641358686
      }
    },
    {
      "id": "worker_3",
      "position": {
        "x": 890.7942000937602,
        "y": 1178.1262984758218
      },
      "type": "customNode",
      "data": {
        "id": "worker_3",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_3-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_3-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_3-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_3-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_3-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_3-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_3-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "Predictor",
          "workerPrompt": "You are the Prediction Agent, responsible for generating accurate forecasts using the most suitable models and approaches. Follow prompts precisely and provide alternative suggestions when necessary. Review outputs and mark them as pending if not approved by the Supervisor. Maintain temporal awareness by considering both historical and future data in your predictions",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 727,
      "selected": false,
      "positionAbsolute": {
        "x": 890.7942000937602,
        "y": 1178.1262984758218
      },
      "dragging": false
    },
    {
      "id": "worker_4",
      "position": {
        "x": 1266.7324739992068,
        "y": 1193.1560029368845
      },
      "type": "customNode",
      "data": {
        "id": "worker_4",
        "label": "Worker",
        "version": 2,
        "name": "worker",
        "type": "Worker",
        "hideOutput": true,
        "baseClasses": [
          "Worker"
        ],
        "category": "Multi Agents",
        "inputParams": [
          {
            "label": "Worker Name",
            "name": "workerName",
            "type": "string",
            "placeholder": "Worker",
            "id": "worker_4-input-workerName-string",
            "display": true
          },
          {
            "label": "Worker Prompt",
            "name": "workerPrompt",
            "type": "string",
            "rows": 4,
            "default": "You are a research assistant who can search for up-to-date info using search engine.",
            "id": "worker_4-input-workerPrompt-string",
            "display": true
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "worker_4-input-promptValues-json",
            "display": true
          },
          {
            "label": "Max Iterations",
            "name": "maxIterations",
            "type": "number",
            "optional": true,
            "id": "worker_4-input-maxIterations-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "worker_4-input-tools-Tool",
            "display": true
          },
          {
            "label": "Supervisor",
            "name": "supervisor",
            "type": "Supervisor",
            "id": "worker_4-input-supervisor-Supervisor",
            "display": true
          },
          {
            "label": "Tool Calling Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "optional": true,
            "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat. If not specified, supervisor's model will be used",
            "id": "worker_4-input-model-BaseChatModel",
            "display": true
          }
        ],
        "inputs": {
          "workerName": "Sentimental ",
          "workerPrompt": "As the Sentimental Agent within our educational analytics framework, your mission is to analyze and classify the emotional content in educational text data with precision and insight. Your role is crucial in transforming raw feedback into actionable emotional intelligence that informs educational interventions and communication strategies.\n\nCore Responsibilities:\n\nSentiment Analysis: Evaluate sentiment in text from student feedback, teacher evaluations, parent communications, and staff interactions.\nSentiment Scoring: Assign precise sentiment scores ranging from -5 (extremely negative) to +5 (extremely positive).\nEmotional Categorization: Utilize our color-coded system to categorize emotional tone: Red (negative), Yellow (neutral), Green (positive), with intensity gradients.\nNuanced Detection: Identify subtle emotional undertones that may not be explicitly stated.\nLanguage Processing: Handle feedback in any language or mixed-language inputs.\nOperational Parameters:\n\nInput Handling: Accept preprocessed text inputs from the Extractor Agent.\nAspect-Based Analysis: Determine sentiment distribution across different aspects (e.g., 70% positive toward teaching methods, 30% negative toward workload).\nTrend Tracking: Monitor sentiment trends when provided with sequential data.\nConfidence Scoring: Provide confidence scores with each sentiment assessment.\nOutput Requirements:\n\nStructured Output: Return structured output with sentiment scores, categories, and confidence levels.\nAspect Breakdown: Include aspect-based sentiment breakdown when multiple topics appear.\nKey Phrase Highlighting: Highlight key phrases that strongly influenced sentiment determination.\nEmotional Tagging: Tag emotional categories beyond positive/negative, such as frustration, enthusiasm, confusion, and gratitude.\nConcise Summarization: Provide a concise summary of overall sentiment for the Response Writer Agent.\nIntegration Behaviors:\n\nContextual Requests: Request additional context from the Extractor Agent when sentiment is ambiguous.\nAlert System: Notify the Predictor Agent upon detecting significant sentiment shifts.\nMetadata Provision: Supply emotional metadata to enhance Response Writer outputs.\nHistory Maintenance: Maintain a processing history to improve consistency in sentiment analysis.\nYour analyses will directly inform educational interventions and communication strategies, making accuracy and consistency in sentiment evaluation critical to",
          "tools": "",
          "supervisor": "{{supervisor_0.data.instance}}",
          "model": "",
          "promptValues": "",
          "maxIterations": ""
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 727,
      "selected": false,
      "positionAbsolute": {
        "x": 1266.7324739992068,
        "y": 1193.1560029368845
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "memoryVectorStore_0",
      "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
      "target": "retrieverTool_1",
      "targetHandle": "retrieverTool_1-input-retriever-BaseRetriever",
      "type": "buttonedge",
      "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-retrieverTool_1-retrieverTool_1-input-retriever-BaseRetriever"
    },
    {
      "source": "openAIEmbeddings_0",
      "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
    },
    {
      "source": "retrieverTool_1",
      "sourceHandle": "retrieverTool_1-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "worker_0",
      "targetHandle": "worker_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "retrieverTool_1-retrieverTool_1-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-worker_0-worker_0-input-tools-Tool"
    },
    {
      "source": "fileLoader_0",
      "sourceHandle": "fileLoader_0-output-document-Document|json",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-document-Document",
      "type": "buttonedge",
      "id": "fileLoader_0-fileLoader_0-output-document-Document|json-memoryVectorStore_0-memoryVectorStore_0-input-document-Document"
    },
    {
      "source": "chatOpenAI_0",
      "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "supervisor_0",
      "targetHandle": "supervisor_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-supervisor_0-supervisor_0-input-model-BaseChatModel"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_0",
      "targetHandle": "worker_0-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_0-worker_0-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_1",
      "targetHandle": "worker_1-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_1-worker_1-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_2",
      "targetHandle": "worker_2-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_2-worker_2-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_3",
      "targetHandle": "worker_3-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_3-worker_3-input-supervisor-Supervisor"
    },
    {
      "source": "supervisor_0",
      "sourceHandle": "supervisor_0-output-supervisor-Supervisor",
      "target": "worker_4",
      "targetHandle": "worker_4-input-supervisor-Supervisor",
      "type": "buttonedge",
      "id": "supervisor_0-supervisor_0-output-supervisor-Supervisor-worker_4-worker_4-input-supervisor-Supervisor"
    }
  ]
}